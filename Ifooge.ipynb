{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTgcz9BSM0PfvFRiL3IvDD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kainatquaderee/Ifooge/blob/main/Ifooge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep active"
      ],
      "metadata": {
        "id": "WTvdjKrsF9zV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep Colab notebook active\n",
        "from google.colab import output\n",
        "\n",
        "code = '''\n",
        "function KeepColabAlive() {\n",
        "    setInterval(() => {\n",
        "        console.log(\"Colab is running\");\n",
        "        document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "    }, 60000); // Change the interval if needed (60000 ms = 1 minute)\n",
        "}\n",
        "KeepColabAlive();\n",
        "'''\n",
        "\n",
        "output.eval_js(code)\n",
        "print(\"KeepAlive script is running\")"
      ],
      "metadata": {
        "id": "DjUGNX_sCKv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# version 1"
      ],
      "metadata": {
        "id": "4GGPKOvFEbIw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjTHWta7BJqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "43f66274-96d4-4bbe-cbbb-51d27af5e98f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-ea0c96222b63>, line 107)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-ea0c96222b63>\"\u001b[0;36m, line \u001b[0;32m107\u001b[0m\n\u001b[0;31m    with\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers diffusers gradio\n",
        "!pip install git+https://github.com/TencentARC/GFPGAN.git\n",
        "!pip install basicsr\n",
        "!pip install git+https://github.com/xinntao/Real-ESRGAN.git\n",
        "\n",
        "# Fix the import issue in basicsr library\n",
        "!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.*/dist-packages/basicsr/data/degradations.py\n",
        "\n",
        "# Keep Colab notebook active\n",
        "from google.colab import output\n",
        "\n",
        "code = '''\n",
        "function KeepColabAlive() {\n",
        "    setInterval(() => {\n",
        "        console.log(\"Colab is running\");\n",
        "        document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "    }, 60000); // Change the interval if needed (60000 ms = 1 minute)\n",
        "}\n",
        "KeepColabAlive();\n",
        "'''\n",
        "\n",
        "output.eval_js(code)\n",
        "print(\"KeepAlive script is running\")\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "import gradio as gr\n",
        "from gfpgan import GFPGANer\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load GFPGAN for face restoration\n",
        "gfpgan = GFPGANer(\n",
        "    model_path='https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth',\n",
        "    upscale=1,\n",
        "    arch='clean',\n",
        "    channel_multiplier=2,\n",
        "    bg_upsampler=None\n",
        ")\n",
        "\n",
        "# Function to fix faces\n",
        "def fix_faces_func(image):\n",
        "    image = np.array(image)\n",
        "    _, _, restored_image = gfpgan.enhance(image, has_aligned=False, only_center_face=False)\n",
        "    return Image.fromarray(restored_image)\n",
        "\n",
        "# Function to load model from Hugging Face\n",
        "def load_model(model_id):\n",
        "    global pipe, img2img_pipe\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "    pipe.safety_checker = dummy_checker\n",
        "    img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "    img2img_pipe.to(\"cuda\")\n",
        "    img2img_pipe.safety_checker = dummy_checker\n",
        "\n",
        "# Remove the safety checker\n",
        "def dummy_checker(images, **kwargs):\n",
        "    return images, [False] * len(images)\n",
        "\n",
        "# Function to generate images\n",
        "def generate_image(model_id, prompt=\"\", negative_prompt=\"lowres, bad quality, deformed, disfigured\", num_inference_steps=50, guidance_scale=7.5, fix_faces=False):\n",
        "    load_model(model_id)\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        # Generate initial image\n",
        "        image = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "    if fix_faces:\n",
        "        image = fix_faces_func(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to generate images from an input image\n",
        "def generate_img2img(model_id, init_image, prompt=\"\", negative_prompt=\"lowres, bad quality, deformed, disfigured\", num_inference_steps=50, guidance_scale=7.5, denoising_strength=0.75, fix_faces=False):\n",
        "    load_model(model_id)\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        # Generate image from input image\n",
        "        image = img2img_pipe(prompt, negative_prompt=negative_prompt, init_image=init_image, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, strength=denoising_strength).images[0]\n",
        "\n",
        "    if fix_faces:\n",
        "        image = fix_faces_func(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Custom CSS for a black modern theme\n",
        "css = \"\"\"\n",
        "body {background-color: #121212; color: #ffffff;}\n",
        ".gradio-container {background-color: #121212 !important; border-color: #333333 !important;}\n",
        ".gr-button {background-color: #333333 !important; color: #ffffff !important; border-color: #333333 !important;}\n",
        ".gr-button:hover {background-color: #444444 !important; border-color: #444444 !important;}\n",
        ".gr-textbox {background-color: #1f1f1f !important; color: #ffffff !important; border-color: #333333 !important;}\n",
        ".gr-slider {color: #ffffff !important;}\n",
        ".gr-checkbox label {color: #ffffff !important;}\n",
        "\"\"\"\n",
        "\n",
        "# Create a Gradio interface with two tabs\n",
        "iface = gr.Blocks(css=css)\n",
        "\n",
        "with iface:\n",
        "    gr.Markdown(\"# ifooge\\nGenerate images using Stable Diffusion and GFPGAN. By Kaiden Quinart.\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Text-to-Image\"):\n",
        "            gr.Markdown(\"## Text-to-Image\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    model_id = gr.Textbox(label=\"Hugging Face Model ID\", value=\"stablediffusionapi/realistic-vision-vae-5\")\n",
        "                    prompt = gr.Textbox(label=\"Prompt Details\")\n",
        "                    negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"lowres, bad quality, deformed, disfigured\")\n",
        "                    num_inference_steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=50, step=1)\n",
        "                    guidance_scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=20.0, value=7.5)\n",
        "                    fix_faces = gr.Checkbox(label=\"Fix Faces\")\n",
        "                with gr.Column():\n",
        "                    generate_button = gr.Button(\"Generate Image\")\n",
        "                    output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "            generate_button.click(generate_image, inputs=[model_id, prompt, negative_prompt, num_inference_steps, guidance_scale, fix_faces], outputs=output_image)\n",
        "\n",
        "        with gr.TabItem(\"Image-to-Image\"):\n",
        "            gr.Markdown(\"## Image-to-Image\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    model_id_img2img = gr.Textbox(label=\"Hugging Face Model ID\", value=\"stablediffusionapi/realistic-vision-vae-5\")\n",
        "                    init_image = gr.Image(label=\"Initial Image\")\n",
        "                    prompt_img2img = gr.Textbox(label=\"Prompt Details\")\n",
        "                    negative_prompt_img2img = gr.Textbox(label=\"Negative Prompt\", value=\"lowres, bad quality, deformed, disfigured\")\n",
        "                    num_inference_steps_img2img = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=50, step=1)\n",
        "                    guidance_scale_img2img = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=20.0, value=7.5)\n",
        "                    denoising_strength = gr.Slider(label=\"Denoising Strength\", minimum=0.0, maximum=1.0, value=0.75)\n",
        "                    fix_faces_img2img = gr.Checkbox(label=\"Fix Faces\")\n",
        "                with gr.Column():\n",
        "                    generate_button_img2img = gr.Button(\"Generate Image\")\n",
        "                    output_image_img2img = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "            generate_button_img2img.click(generate_img2img, inputs=[model_id_img2img, init_image, prompt_img2img, negative_prompt_img2img, num_inference_steps_img2img, guidance_scale_img2img, denoising_strength, fix_faces_img2img], outputs=output_image_img2img)\n",
        "\n",
        "# Launch the interface with debug mode enabled\n",
        "iface.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# version 2"
      ],
      "metadata": {
        "id": "HrDtfJ_3ErK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers diffusers gradio safetensors\n",
        "!pip install git+https://github.com/TencentARC/GFPGAN.git\n",
        "!pip install basicsr\n",
        "!pip install git+https://github.com/xinntao/Real-ESRGAN.git\n",
        "\n",
        "# Fix the import issue in basicsr library\n",
        "!sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/lib/python3.*/dist-packages/basicsr/data/degradations.py\n",
        "\n",
        "# Keep Colab notebook active\n",
        "from google.colab import output\n",
        "\n",
        "code = '''\n",
        "function KeepColabAlive() {\n",
        "    setInterval(() => {\n",
        "        console.log(\"Colab is running\");\n",
        "        document.querySelector(\"colab-toolbar-button#connect\").click();\n",
        "    }, 60000); // Change the interval if needed (60000 ms = 1 minute)\n",
        "}\n",
        "KeepColabAlive();\n",
        "'''\n",
        "\n",
        "output.eval_js(code)\n",
        "print(\"KeepAlive script is running\")\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "import gradio as gr\n",
        "from gfpgan import GFPGANer\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import wget\n",
        "\n",
        "# Load GFPGAN for face restoration\n",
        "gfpgan = GFPGANer(\n",
        "    model_path='https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth',\n",
        "    upscale=1,\n",
        "    arch='clean',\n",
        "    channel_multiplier=2,\n",
        "    bg_upsampler=None\n",
        ")\n",
        "\n",
        "# Function to fix faces\n",
        "def fix_faces_func(image):\n",
        "    image = np.array(image)\n",
        "    _, _, restored_image = gfpgan.enhance(image, has_aligned=False, only_center_face=False)\n",
        "    return Image.fromarray(restored_image)\n",
        "\n",
        "# Function to download model from Civitai locally\n",
        "def download_model_from_civitai(civitai_url):\n",
        "    file_name = civitai_url.split(\"/\")[-1]\n",
        "    wget.download(civitai_url, file_name)\n",
        "    return file_name\n",
        "\n",
        "# Function to load model from local path\n",
        "def load_model_from_local(model_path):\n",
        "    global pipe, img2img_pipe\n",
        "    pipe = StableDiffusionPipeline.from_single_file(model_path, torch_dtype=torch.float16)\n",
        "    img2img_pipe = StableDiffusionImg2ImgPipeline.from_single_file(model_path, torch_dtype=torch.float16)\n",
        "    pipe.to(\"cuda\")\n",
        "    img2img_pipe.to(\"cuda\")\n",
        "    pipe.safety_checker = dummy_checker\n",
        "    img2img_pipe.safety_checker = dummy_checker\n",
        "\n",
        "# Function to load model from Hugging Face or Civitai\n",
        "def load_model(model_id, from_civitai=False):\n",
        "    if from_civitai:\n",
        "        model_path = download_model_from_civitai(model_id)\n",
        "        load_model_from_local(model_path)\n",
        "    else:\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "        pipe.to(\"cuda\")\n",
        "        pipe.safety_checker = dummy_checker\n",
        "        img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
        "        img2img_pipe.to(\"cuda\")\n",
        "        img2img_pipe.safety_checker = dummy_checker\n",
        "\n",
        "# Remove the safety checker\n",
        "def dummy_checker(images, **kwargs):\n",
        "    return images, [False] * len(images)\n",
        "\n",
        "# Function to generate images\n",
        "def generate_image(model_id, from_civitai, prompt=\"\", negative_prompt=\"lowres, bad quality, deformed, disfigured\", num_inference_steps=50, guidance_scale=7.5, fix_faces=False):\n",
        "    load_model(model_id, from_civitai)\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        # Generate initial image\n",
        "        image = pipe(prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
        "\n",
        "    if fix_faces:\n",
        "        image = fix_faces_func(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Function to generate images from an input image\n",
        "def generate_img2img(model_id, from_civitai, init_image, prompt=\"\", negative_prompt=\"lowres, bad quality, deformed, disfigured\", num_inference_steps=50, guidance_scale=7.5, denoising_strength=0.75, fix_faces=False):\n",
        "    load_model(model_id, from_civitai)\n",
        "    init_image = init_image.convert(\"RGB\")\n",
        "    init_image = init_image.resize((512, 512))\n",
        "    with torch.autocast(\"cuda\"):\n",
        "        # Generate image from input image\n",
        "        image = img2img_pipe(prompt, negative_prompt=negative_prompt, init_image=init_image, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, strength=denoising_strength).images[0]\n",
        "\n",
        "    if fix_faces:\n",
        "        image = fix_faces_func(image)\n",
        "\n",
        "    return image\n",
        "\n",
        "# Custom CSS for a black modern theme\n",
        "css = \"\"\"\n",
        "body {background-color: #121212; color: #ffffff;}\n",
        ".gradio-container {background-color: #121212 !important; border-color: #333333 !important;}\n",
        ".gr-button {background-color: #333333 !important; color: #ffffff !important; border-color: #333333 !important;}\n",
        ".gr-button:hover {background-color: #444444 !important; border-color: #444444 !important;}\n",
        ".gr-textbox {background-color: #1f1f1f !important; color: #ffffff !important; border-color: #333333 !important;}\n",
        ".gr-slider {color: #ffffff !important;}\n",
        ".gr-checkbox label {color: #ffffff !important;}\n",
        "\"\"\"\n",
        "\n",
        "# Create a Gradio interface with two tabs\n",
        "iface = gr.Blocks(css=css)\n",
        "\n",
        "with iface:\n",
        "    gr.Markdown(\"# ifooge\\nGenerate images using Stable Diffusion and GFPGAN. By Kaiden Quinart.\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"Text-to-Image\"):\n",
        "            gr.Markdown(\"## Text-to-Image\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    model_id = gr.Textbox(label=\"Model ID (Hugging Face)\", value=\"stablediffusionapi/realistic-vision-vae-5\")\n",
        "                    model_path_civitai = gr.Textbox(label=\"Model Path (Civitai)\", placeholder=\"Enter URL to Civitai model\", type=\"text\")\n",
        "                    use_civitai = gr.Checkbox(label=\"Use Civitai\")\n",
        "                    prompt = gr.Textbox(label=\"Prompt Details\")\n",
        "                    negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"lowres, bad quality, deformed, disfigured\")\n",
        "                    num_inference_steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=50, step=1)\n",
        "                    guidance_scale = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=20.0, value=7.5)\n",
        "                    fix_faces = gr.Checkbox(label=\"Fix Faces\")\n",
        "                with gr.Column():\n",
        "                    generate_button = gr.Button(\"Generate Image\")\n",
        "                    output_image = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "            generate_button.click(generate_image, inputs=[model_id, use_civitai, prompt, negative_prompt, num_inference_steps, guidance_scale, fix_faces], outputs=output_image)\n",
        "\n",
        "        with gr.TabItem(\"Image-to-Image\"):\n",
        "            gr.Markdown(\"## Image-to-Image\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    model_id_img2img = gr.Textbox(label=\"Model ID (Hugging Face)\", value=\"stablediffusionapi/realistic-vision-vae-5\")\n",
        "                    model_path_civitai_img2img = gr.Textbox(label=\"Model Path (Civitai)\", placeholder=\"Enter URL to Civitai model\", type=\"text\")\n",
        "                    use_civitai_img2img = gr.Checkbox(label=\"Use Civitai\")\n",
        "                    init_image = gr.Image(label=\"Initial Image\")\n",
        "                    prompt_img2img = gr.Textbox(label=\"Prompt Details\")\n",
        "                    negative_prompt_img2img = gr.Textbox(label=\"Negative Prompt\", value=\"lowres, bad quality, deformed, disfigured\")\n",
        "                    num_inference_steps_img2img = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=50, step=1)\n",
        "                    guidance_scale_img2img = gr.Slider(label=\"Guidance Scale\", minimum=0.1, maximum=20.0, value=7.5)\n",
        "                    denoising_strength = gr.Slider(label=\"Denoising Strength\", minimum=0.0, maximum=1.0, value=0.75)\n",
        "                    fix_faces_img2img = gr.Checkbox(label=\"Fix Faces\")\n",
        "                with gr.Column():\n",
        "                    generate_button_img2img = gr.Button(\"Generate Image\")\n",
        "                    output_image_img2img = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "            generate_button_img2img.click(generate_img2img, inputs=[model_id_img2img, use_civitai_img2img, init_image, prompt_img2img, negative_prompt_img2img, num_inference_steps_img2img, guidance_scale_img2img, denoising_strength, fix_faces_img2img], outputs=output_image_img2img)\n",
        "\n",
        "# Launch the interface with debug mode enabled\n",
        "iface.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "9CxGqGYuEv4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}